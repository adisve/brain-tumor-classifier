{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.utils import Utils as ut\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LambdaCallback\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications import EfficientNetB0, DenseNet121, MobileNetV2, ResNet50\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.metrics import AUC\n",
    "from keras.layers import Dropout, Dense, GlobalAveragePooling2D, Flatten, LeakyReLU, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['glioma', 'meningioma', 'no_tumor', 'pituitary']\n",
    "testing_dir = 'Testing/'\n",
    "training_dir = 'Training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = ut.get_subfolders(training_dir)\n",
    "ut.display_images_from_subfolders(training_dir, subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = ut.load_data(training_dir, labels)\n",
    "X_test, y_test = ut.load_data(testing_dir, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "y_train = to_categorical(y_train) # One-hot encoding of integer labels\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 20% of the data is validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "image_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'EfficientNet': ut.build_and_compile_model('EfficientNet', 224),\n",
    "    'DenseNet': ut.build_and_compile_model('DenseNet', 224),\n",
    "    'MobileNet': ut.build_and_compile_model('MobileNet', 224),\n",
    "    'ResNet50': ut.build_and_compile_model('ResNet50', 224)\n",
    "}\n",
    "\n",
    "ut.display_summaries(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = ut.train_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, history in history_dict.items():\n",
    "    ut.plot('loss', history)\n",
    "    ut.plot('accuracy', history)\n",
    "    ut.plot('auc', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    predicted_classes = np.argmax(model.predict(X_test), axis=1)\n",
    "    confusionmatrix = confusion_matrix(np.argmax(y_test,axis=1), predicted_classes)\n",
    "    plt.figure(figsize = (16, 16))\n",
    "    sns.heatmap(confusionmatrix, cmap='Blues', annot=True, cbar=True)\n",
    "\n",
    "    print(classification_report(np.argmax(y_test,axis=1), predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    loss, acc, auc = model.evaluate(X_test, y_test)\n",
    "    metrics_list.append([model_name, f\"{acc * 100:.2f}%\", f\"{auc * 100:.2f}%\", f\"{loss:.2f}\"])\n",
    "\n",
    "df = pd.DataFrame(metrics_list, columns=[\"Model\", \"Accuracy (%)\", \"AUC (%)\", \"Loss\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # First Conv Block\n",
    "    Conv2D(32, (3, 3), kernel_initializer='he_normal', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second Conv Block\n",
    "    Conv2D(64, (3, 3), kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Third Conv Block\n",
    "    Conv2D(128, (3, 3), kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # New Fourth Conv Block\n",
    "    Conv2D(256, (3, 3), kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # New Fifth Conv Block\n",
    "    Conv2D(512, (3, 3), kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    Flatten(),\n",
    "    Dense(128, kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(64, kernel_initializer='he_normal'),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(alpha=0.01),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(4, activation='softmax', kernel_regularizer=l2(0.01))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ut.train_model('bt_cnn', image_gen, X_train, y_train, X_val, y_val, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

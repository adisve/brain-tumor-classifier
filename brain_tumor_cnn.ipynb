{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import functional as F\n","from torchvision.models import resnet18\n","from torchvision import transforms\n","from skimage.io import imsave\n","from skimage.io import imread\n","from copy import deepcopy\n","from tqdm import tqdm\n","from torch import nn\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import pydicom\n","import random\n","import torch\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Set hyperparameters and constant values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TRAIN_DIR = 'Training/'\n","TEST_DIR = 'Testing/'\n","IMG_SIZE = 224\n","TRAIN_BATCHSIZE = 200\n","EVAL_BATCHSIZE = 10\n","EPOCHS = 10\n","TRAIN_FRACTION = 0.8\n","TEST_FRACTION = 0.1\n","VALIDATION_FRACTION = 0.1\n","DATA_LABELS = {0: 'glioma', 1: 'meningioma', 2: 'no_tumor', 3: 'pituitary'}"]},{"cell_type":"markdown","metadata":{},"source":["## Create class for handling Training and Testing datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class BrainTumorDataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.labels = None\n","        \n","        self.create_labels()\n","\n","    # Create labels for each image\n","    def create_labels(self):\n","        labels = []\n","        for target, target_label in DATA_LABELS.items():\n","            case_dir = os.path.join(self.data_dir, target_label)\n","            for fname in os.listdir(case_dir):\n","                fpath = os.path.join(case_dir, fname)\n","                labels.append((fpath, target))\n","        self.labels = labels\n","\n","    # Normalize image to 0-255 range         \n","    def normalize(self, img):\n","        img = img.astype(np.float_) * 255. / img.max()\n","        img = img.astype(np.uint8)\n","        return img\n","\n","    # Returns data with its label \n","    def __getitem__(self, idx):\n","        fpath, target = self.labels[idx]\n","        \n","        img_arr = imread(fpath, as_gray=True)\n","        img_arr = self.normalize(img_arr)\n","        \n","        data = torch.from_numpy(img_arr)\n","        data = data.type(torch.FloatTensor)\n","        data = torch.unsqueeze(data, 0)\n","        \n","        if self.transform:\n","            data = self.transform(data)\n","        \n","        return data, target\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"markdown","metadata":{},"source":["## Create transforms which will augment images in datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomRotation(10),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.RandomPerspective(distortion_scale=0.2, p=0.5, interpolation=3),\n","    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["## Define function for plotting images in datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def plot_sample_images(dataset, num_samples_per_class=4):\n","    samples = {label: [] for _, label in dataset.labels}\n","    \n","    for img_path, label in dataset.labels:\n","        if all(len(samples[label]) >= num_samples_per_class for label in samples):\n","            break\n","\n","        if len(samples[label]) < num_samples_per_class:\n","            img = imread(img_path, as_gray=True)\n","            samples[label].append(img)\n","    \n","    fig, axes = plt.subplots(len(samples), num_samples_per_class, figsize=(15, 10))\n","    for i, label in enumerate(samples.keys()):\n","        for j, img in enumerate(samples[label]):\n","            axes[i, j].imshow(img, cmap='gray')\n","            axes[i, j].axis('off')\n","            if j == 0:\n","                axes[i, j].set_title(DATA_LABELS[label])\n","    \n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Instantiate dataset classes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = BrainTumorDataset(data_dir=TRAIN_DIR, transform=train_transform)\n","test_dataset_full = BrainTumorDataset(data_dir=TEST_DIR, transform=test_transform)\n","\n","plot_sample_images(dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Create testing and validation datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["total_test_samples = len(test_dataset_full)\n","TEST_FRACTION = int(total_test_samples * 0.7)  # 70% for testing\n","VALIDATION_FRACTION = total_test_samples - TEST_FRACTION  # remaining for validation\n","\n","test_dataset, validation_dataset = torch.utils.data.random_split(\n","    test_dataset_full, \n","    [TEST_FRACTION, VALIDATION_FRACTION]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f'Running on {device}')"]},{"cell_type":"markdown","metadata":{},"source":["## Create data loaders for trainig, testing, and validation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_loader = DataLoader(\n","    train_dataset, \n","    batch_size=TRAIN_BATCHSIZE,\n","    shuffle=True\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset, \n","    batch_size=EVAL_BATCHSIZE\n",")\n","\n","validation_loader = DataLoader(\n","    validation_dataset, \n","    batch_size=EVAL_BATCHSIZE\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["net = resnet18()\n","net.conv1 = nn.Conv2d(\n","    1, \n","    64, \n","    kernel_size=(7, 7), \n","    stride=(2, 2), padding=(3, 3), bias=False\n",")\n","\n","net = net.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","error_minimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n","\n","net_final = deepcopy(net)"]},{"cell_type":"markdown","metadata":{},"source":["## Training loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_validation_accuracy = 0. \n","train_accs = []\n","val_accs = []\n","\n","for epoch in range(EPOCHS):\n","    net.train()  # Set the network in training mode\n","\n","    print(f\"# Epoch {epoch + 1}:\")\n","\n","    total_train_examples = 0\n","    num_correct_train = 0\n","\n","    for batch_index, (inputs, targets) in enumerate(train_loader):\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        # Zero the parameter gradients\n","        error_minimizer.zero_grad()\n","\n","        # Forward pass\n","        predictions = net(inputs)\n","\n","        # Compute loss\n","        loss = criterion(predictions, targets)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        error_minimizer.step()\n","\n","        # Compute training accuracy\n","        _, predicted_class = predictions.max(1)\n","        total_train_examples += predicted_class.size(0)\n","        num_correct_train += predicted_class.eq(targets).sum().item()\n","\n","    train_acc = num_correct_train / total_train_examples\n","    print(f\"Training accuracy: {train_acc}\")\n","    train_accs.append(train_acc)\n","    \n","    total_val_examples = 0\n","    num_correct_val = 0\n","    \n","    net.eval()\n","\n","    with torch.no_grad():\n","        for batch_index, (inputs, targets) in enumerate(validation_loader):\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","            \n","            predictions = net(inputs)\n","            _, predicted_class = predictions.max(1)\n","            \n","            total_val_examples += predicted_class.size(0)\n","            num_correct_val += predicted_class.eq(targets).sum().item()\n","\n","    val_acc = num_correct_val / total_val_examples\n","    print(f\"Validation accuracy: {val_acc}\")\n","    val_accs.append(val_acc)\n","\n","    if val_acc > best_validation_accuracy:\n","       best_validation_accuracy = val_acc\n","       print(\"Validation accuracy was improved. Saving new model.\")\n","       net_final = deepcopy(net)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Testing loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["net.eval()\n","\n","total_test_examples = 0\n","num_correct_test = 0\n","\n","with torch.no_grad():\n","    for batch_index, (inputs, targets) in enumerate(test_loader):\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        \n","        predictions = net(inputs)\n","        _, predicted_class = predictions.max(1)\n","        \n","        total_test_examples += predicted_class.size(0)\n","        num_correct_test += predicted_class.eq(targets).sum().item()\n","\n","test_acc = num_correct_test / total_test_examples\n","print(f\"Test accuracy: {test_acc}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","epochs_list = list(range(EPOCHS))\n","\n","plt.figure()\n","plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n","plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n","plt.xlabel('epoch')\n","plt.ylabel('prediction accuracy')\n","plt.ylim(0.5, 1)\n","plt.title('Classifier training evolution:\\nprediction accuracy over time')\n","plt.legend()\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":2}
